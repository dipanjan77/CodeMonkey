{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing with data frames in a DataBricks cluster\n",
    "### This notebook needs a databricks cluster to execute. Cannot run on local Jupyter notebook\n",
    "#### This tutorial is part of \"A Gentle Introduction to Spark\" by Databricks\n",
    "The pdf url is:\n",
    "https://pages.databricks.com/rs/094-YMS-629/images/A-Gentle-Introduction-to-Apache-Spark.pdf?mkt_tok=eyJpIjoiWXpsbVlqVXpaV1psWlRsaCIsInQiOiJ1VWNPYnQxZjUxR3Y0a2o2ZzFZQ0ZWVjU0M1pKOW9MNzFvR3Q3Ymx1ZlY1XC9qbjVyUzQzRVk1ek5kWGF5a3JXTXNPd3Y1SENEM1k1eUpqVFRIYkkrb0pvUGVxbTlOM3NNQWEwemo2K29lZVpsRnVzdW1xbjRBTm5KRHZuUFJuSFgifQ%3D%3D\n",
    "\n",
    "Data Location:\n",
    "https://github.com/databricks/Spark-The-Definitive-Guide/tree/master/data/flight-data/csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mytable = spark.table(\"summary2015\")\n",
    "display(mytable.select(\"*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbutils.fs.mount(\n",
    "  source = \"wasbs://flight-data@datasets4ml.blob.core.windows.net/\",\n",
    "  mount_point = \"/mnt/flight-data\",\n",
    "  extra_configs = {\"fs.azure.account.key.datasets4ml.blob.core.windows.net\": \"1fuQZXeZ2GOr+3Dg0VDYy40gzoWWni4SepuX7I3X5feZFaWaJ/hKLlfhrREJ4odVwWQJf+Z9gAuJsyDX+aS4Sw==\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "flightData2015=spark\\\n",
    "  .read\\\n",
    "  .option(\"inferSchema\",\"true\")\\\n",
    "  .option(\"header\",\"true\")\\\n",
    "  .csv(\"/mnt/flight-data/2015-summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flightData2015.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flightData2015.sort(\"count\").explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.shuffle.partitions\",\"5\")\n",
    "flightData2015.sort(\"count\").take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flightData2015.createOrReplaceTempView(\"flight_data_2015\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqlWay=spark.sql(\"\"\"\n",
    "              SELECT DEST_COUNTRY_NAME, count(1) \n",
    "              FROM flight_data_2015\n",
    "              GROUP BY DEST_COUNTRY_NAME\n",
    "              \"\"\")\n",
    "\n",
    "dataFrameWay=flightData2015\\\n",
    "            .groupBy(\"DEST_COUNTRY_NAME\")\\\n",
    "            .count()\n",
    "#display(sqlWay)\n",
    "#display(dataFrameWay)\n",
    "\n",
    "sqlWay.explain()\n",
    "dataFrameWay.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "name": "dipanbTest",
  "notebookId": 1671668795429375
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
